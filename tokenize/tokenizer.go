// Package tokenize provides various tools for tokenization
// including word dicing and text segmentation.
package tokenize

import (
	"fmt"
)

func New() interface{} {
	fmt.Println("New Tokenizer...")
	return nil
}
